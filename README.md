# Optimizing an ML Pipeline in Azure

## Overview
This project is part of the Udacity Azure ML Nanodegree.
In this project, we build and optimize an Azure ML pipeline using the Python SDK and a provided Scikit-learn model.
This model is then compared to an Azure AutoML run.

## Summary
The dataset provided by UCI Machine Learning Repostory contains information regarding direct bank marketing campaigns. More specifically, it contains information about the age, job, day of contact, contact type such as telephone and how long a banking clerk had contact with (potential) customers. Based on those information we seek to predict if a client subscribet to a term deposit after contact.

The best performing model was a VotingEnsemble obtained by AutoML, which performed  

## Scikit-learn Pipeline
The pipeline architecture consisted of downloading the data followed by cleaning the data. More specifically, one-hot encoding of categorical attributes, remove data records with missing values, and splitting data into training and test data according to a splitting ratio of 0.8:0.2. As the dataset is a binary classification problem, logistic regression will serve as a fairly simple but powerful baseline model.

Using HyperDrive, a hyperparameter tuning framework originally proposed by [Rasley et al. at Middleware â€™17 conference](https://dl.acm.org/doi/10.1145/3135974.3135994), we tune exactly two hyperparameter, namely the regularization strength and the maximum number of iterations it will take to converge.

The first hyperparameter, regularization strength, is a floating number. Thus, a random parameter sampler using a uniform distribution is  used for this hyperparameter. In the case of maximun number of iterations, which inherently is an integer value, the random sampler selects from a predefined number of iterations. More specifically, prime numbers between 11 and 59. 

When comparing grid search and random search, the latter finds good hyperparameters more quickly. Therefore, in this scenario a random parameter sampler has been chosen.

Furthermore, as an early stopping stragety bandit policy was selected. Such a bandit policy is defined by three parameters: slack factor, evaluation interval, and delay evaluation. The *slack factor* specifies a ratio in which it is allowed to differ from the best performing model so far in an experiment run. The *evaluation interval* specifies the frequency in which this particular policy is applied, and *delay evaluation* determines the number of dormant intervals before this policy is applied again. Therefore, *delay evaluation* helps to avoid premature termination of training runs. With an slack factor of 0.1, evaluation interval of one, and a delay evaluation of 3 we seek to find a good logistic regression with this early stopping strategy.

## AutoML
**In 1-2 sentences, describe the model and hyperparameters generated by AutoML.**

## Pipeline comparison
**Compare the two models and their performance. What are the differences in accuracy? In architecture? If there was a difference, why do you think there was one?**

## Future work
**What are some areas of improvement for future experiments? Why might these improvements help the model?**
